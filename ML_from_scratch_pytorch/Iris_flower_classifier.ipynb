{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_neurons, inputs_per_neuron): \n",
    "        self.num_neurons = num_neurons\n",
    "        self.w = torch.randn(num_neurons, inputs_per_neuron, requires_grad=True, dtype=torch.float32)\n",
    "        self.b = torch.randn(num_neurons, 1, requires_grad=True, dtype=torch.float32)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = ((self.w @ inputs) + self.b)\n",
    "        return out \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_layers, num_inputs, num_neurons_per_layer, num_final_out):\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = [Layer(num_neurons_per_layer, num_inputs)]\n",
    "\n",
    "        for _ in range(num_layers): \n",
    "            layer = Layer(num_neurons_per_layer, num_neurons_per_layer)\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        layer_out = Layer(num_final_out, num_neurons_per_layer)\n",
    "        self.layers.append(layer_out)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out_prev = input\n",
    "        for i in range(len(self.layers)):\n",
    "            if i == (len(self.layers)-1):\n",
    "                out_prev = self.layers[i].forward(out_prev)\n",
    "            else:\n",
    "                out_prev = self.layers[i].forward(out_prev).tanh()\n",
    "        return out_prev\n",
    "        \n",
    "    def train(self, epochs, learning_rate, x, y):\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        for _ in range(epochs):\n",
    "            # loss = ((y - self.forward(x))**2).flatten().sum()\n",
    "            y_pred = self.forward(x).view(y.shape[0], y.shape[1])\n",
    "            # print(y_pred.shape, y_pred.dtype)\n",
    "            loss = loss_func(y_pred, y)\n",
    "            print(f\"Loss: {loss}\")\n",
    "            loss.backward()\n",
    "            for layer in self.layers:\n",
    "                layer.w.data -= learning_rate * layer.w.grad\n",
    "                layer.b.data -= learning_rate * layer.b.grad\n",
    "                layer.w.grad = None\n",
    "                layer.b.grad = None\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "epochs = 2000\n",
    "learning_rate = 0.02\n",
    "num_neurons_per_layer = 10\n",
    "num_layers = 2\n",
    "train_split = 0.90\n",
    "batch_size = int(150*train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(batch_size):\n",
    "    headers=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"name\"]\n",
    "    data = pd.read_csv(\"/Users/adityatandon/Documents/VS Code/Learn ML/Data/iris.data\", names=headers).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    dataset_size = len(data) # 150\n",
    "    num_classifications = len(set(data.name)) # 3\n",
    "    num_features = len(data.columns) - 1 # 4\n",
    "\n",
    "    rand_seed_idx = torch.randint((dataset_size - batch_size), (1,)).item() #generates a tensor with a random integer and extracts it using .item()\n",
    "    training_data = data[rand_seed_idx : rand_seed_idx+batch_size].reset_index(drop=True, inplace=False)\n",
    "\n",
    "    diff_flowers = set(data.name)\n",
    "    classification = []\n",
    "    for idx in range(len(training_data['name'])):\n",
    "        if training_data.name[idx] == \"Iris-setosa\":\n",
    "            classification.append([1,0,0])\n",
    "        elif training_data.name[idx] == \"Iris-versicolor\":\n",
    "            classification.append([0,1,0])\n",
    "        elif training_data.name[idx] == \"Iris-virginica\":\n",
    "            classification.append([0,0,1])\n",
    "    \n",
    "    training_data['classification'] = classification\n",
    "    features_list=[]\n",
    "    for i in range(num_features):\n",
    "        features_list.append(torch.tensor(training_data.iloc(axis=1)[i].tolist()).reshape(len(training_data.iloc(axis=1)[0].tolist()), 1)) \n",
    "\n",
    "    train_in = torch.cat(features_list, dim=1)\n",
    "    train_out = torch.tensor(training_data['classification'].tolist(), dtype=torch.float32)\n",
    "    train_in = train_in.reshape(batch_size, num_features, 1)\n",
    "    train_out = train_out.reshape(batch_size, num_classifications)\n",
    "\n",
    "    examples = train_split * dataset_size\n",
    "    num_inputs = num_features\n",
    "    num_outputs = num_classifications\n",
    "\n",
    "    return train_in, train_out, num_features, num_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in, train_out, num_features, num_classifications = datagen(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLP(num_layers=3, num_inputs=num_features, num_neurons_per_layer=num_neurons_per_layer, num_final_out=num_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(epochs, learning_rate, train_in, train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = classifier.forward(train_in).view(train_out.shape[0], train_out.shape[1])\n",
    "out.softmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
