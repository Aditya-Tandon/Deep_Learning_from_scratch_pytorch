{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.backends.mps\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pylab as pylab\n",
    "from torch.autograd.anomaly_mode import set_detect_anomaly\n",
    "\n",
    "params = {'font.size' : 16 }\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 1\n",
    "padding_size = 2\n",
    "filter_size = 3\n",
    "step_size = 1\n",
    "num_features = 2\n",
    "num_connected_layers = 10\n",
    "num_conv_layers = 4\n",
    "num_classifications = 10\n",
    "num_neurons_per_layer = 50\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    torch.dtype=torch.float32\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "torch.autograd.anomaly_mode.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multi dimensioanl images with a step size of 1 - 1:1 image to conved_image size; dimensions increase by 2\n",
    "# convolution using a matrix multiplication\n",
    "class Convolver:\n",
    "    def __init__(self, kern, bias, x, device=device):\n",
    "        if(x.dim() <= 2):\n",
    "            self.img = x.unsqueeze(dim=1)\n",
    "        else:\n",
    "            self.img = x\n",
    "        self.w = kern\n",
    "        self.b = bias\n",
    "        self.device = device\n",
    "    \n",
    "    def flatten_pad(self):\n",
    "        pad_size = int((filter_size - 1) / 2) \n",
    "        img = nn.functional.pad(self.img, (pad_size, pad_size, pad_size, pad_size))\n",
    "        n = torch.zeros(2)\n",
    "        for i in range(2):\n",
    "            n[i] = ((img.shape[-i - 1] - filter_size) / step_size) + 1\n",
    "        flat_img = img.flatten().clone().view(img.shape[-4], img.shape[-3], img.shape[-2]*img.shape[-1]).float()\n",
    "        flat_kern = self.w.view(self.w.shape[-3], filter_size * filter_size)\n",
    "        return n, img, flat_img, flat_kern\n",
    "\n",
    "    def change_kern_multi(self):\n",
    "        n, img, flat_img, flat_kern = self.flatten_pad()\n",
    "        new_kern = torch.zeros(self.w.shape[-3] , int(torch.prod(n)), img.shape[-2] * img.shape[-1], device=device) #produces num_feat x n x n convolution\n",
    "        flat_kern = torch.cat([flat_kern for _ in range(1)], dim=0)\n",
    "        for k  in range(new_kern.shape[-3]):\n",
    "            start_idx = 0\n",
    "            for i in range(new_kern.shape[-2]):\n",
    "                j = 0\n",
    "                c = 0\n",
    "                if i == 0:\n",
    "                    start_idx = start_idx\n",
    "                elif i % int(n[0]) != 0:\n",
    "                    start_idx += step_size * step_size\n",
    "                else: \n",
    "                    start_idx = int((i+1-step_size)//int(n[0]) * img.shape[-2])\n",
    "                while j < new_kern.shape[-1] and start_idx+j+filter_size <= new_kern.shape[-1]:\n",
    "                    new_kern[k][i][start_idx + j:start_idx + j + filter_size] = flat_kern[k][c:c + filter_size]\n",
    "                    c += filter_size\n",
    "                    j += img.shape[-2]\n",
    "                    if c == flat_kern.shape[-1]:\n",
    "                        break\n",
    "        return n, new_kern, flat_img\n",
    "    \n",
    "    def convolve(self): #convolves image using a kernel made from self.w\n",
    "        start_time = time.time()\n",
    "        conved_final = []\n",
    "        n, changed_kern, flat_img = self.change_kern_multi()\n",
    "        to_be_cat = [flat_img for _ in range(self.img.shape[-3])]\n",
    "        copy_flat_img = torch.cat(to_be_cat, dim=1).unsqueeze(dim=-2)\n",
    "        for batch in range(self.img.shape[-4]):\n",
    "            conv = [changed_kern @ torch.transpose(copy_flat_img[batch][j], -1, -2) for j in range(self.img.shape[-3])]\n",
    "            conved_final.append(torch.concat(conv, dim=0).squeeze(dim=0))\n",
    "        conved_final = torch.stack(conved_final)\n",
    "        squeezed_convd_mat = conved_final.squeeze(dim=-1)\n",
    "        squeezed_convd_mat += self.b\n",
    "        conv_img = squeezed_convd_mat.reshape(batch_size, self.img.shape[-3] * num_features, int(n[-2]), int(n[-1]))\n",
    "        end_time = time.time()\n",
    "        return conv_img  \n",
    "    \n",
    "    def pool(self, step_size: int, conv_img: torch.tensor):\n",
    "        pool_kern = torch.ones(step_size, step_size, device=self.device)\n",
    "        pool_size = [conv_img.shape[-4], conv_img.shape[-3], int((conv_img.shape[-2] - step_size)/step_size + 1), int((conv_img.shape[-1] - step_size)/step_size + 1)]\n",
    "        pool_img = torch.zeros(pool_size, device=device)\n",
    "        for batch in range(conv_img.shape[-4]):\n",
    "            for feat in range(num_features):\n",
    "                row = 0\n",
    "                for i in range(pool_img.shape[-2]):\n",
    "                    col = 0\n",
    "                    for j in range(pool_img.shape[-1]):\n",
    "                        pixels = conv_img[batch, feat, row:row + step_size, col:col + step_size]\n",
    "                        conv = pixels * pool_kern\n",
    "                        pool_img[feat, i, j] = torch.max(conv)\n",
    "                        col += step_size \n",
    "                    row += step_size \n",
    "        return pool_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_neurons, num_inputs_per_neuron, device):\n",
    "        self.w = torch.randn(num_neurons, num_inputs_per_neuron, dtype=torch.float32, requires_grad=True, device=device) \n",
    "        self.b = torch.randn(num_neurons, 1, dtype=torch.float32, requires_grad=True, device=device) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        outer = ((self.w @ x) + self.b)\n",
    "        out = torch.nn.functional.tanh(outer)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Layer using calling convolver\n",
    "class Conv_layer():\n",
    "    def __init__(self, img, filter_size:int, num_features: int, device=device):\n",
    "        self.device = device\n",
    "        if(img.dim() <= 2):\n",
    "            self.img = img.unsqueeze(dim=0)\n",
    "        else:\n",
    "            self.img = img\n",
    "        self.num_features = num_features\n",
    "        self.w = torch.randn(num_features, filter_size, filter_size, requires_grad=True, dtype=torch.float32, device=self.device) \n",
    "        self.b = torch.randn(1, self.img.shape[-1] * self.img.shape[-2], requires_grad=True, dtype=torch.float32, device=self.device) \n",
    "        self.gamma = torch.randn(1, dtype=torch.float32, device = self.device, requires_grad=True)\n",
    "        self.beta = torch.randn(1, dtype=torch.float32, device = self.device, requires_grad=True)\n",
    "\n",
    "    def convolve(self, image: torch.tensor):\n",
    "        convolver = Convolver(kern=self.w, x=image, bias=self.b)\n",
    "        conv_img = convolver.convolve()\n",
    "        return conv_img\n",
    "    \n",
    "    def forward_relu(self, image: torch.tensor):\n",
    "        conv_img = self.convolve(image) \n",
    "        # conv_img = self.batch_norm(conv_img)\n",
    "        out = torch.nn.functional.tanh(conv_img)\n",
    "        return out\n",
    "    \n",
    "    def batch_norm(self, input):\n",
    "        #TODO: Fix required\n",
    "        conv_img_temp = input.clone()\n",
    "        stack = []\n",
    "        for j in range(conv_img_temp.shape[-4]):\n",
    "            # for i in range(conv_img_temp.shape[-3]):  # Iterate over the channel dimension\n",
    "            mean = torch.mean(conv_img_temp, dim=-3, keepdim=True)\n",
    "            variance = torch.var(conv_img_temp, dim=-3, keepdim=True, unbiased=True)\n",
    "            normal = [(conv_img_temp[j][i] - mean) / torch.sqrt(variance + 1e-8) for i in range(conv_img_temp.shape[-3])]\n",
    "            print(normal[0].shape)\n",
    "            stack.append(torch.concat(normal, dim=0))\n",
    "        conv_img_temp = torch.stack(stack)\n",
    "        return conv_img_temp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, num_conected_layers, num_conv_layers, num_neurons_per_layer, \n",
    "                 num_final_out, datagen, batch_size, device=device):\n",
    "        \n",
    "        self.device = device\n",
    "        self.datagen = datagen(batch_size)\n",
    "        img, _ = self.datagen.data_generator()\n",
    "\n",
    "        self.convlayers = [Conv_layer(img, filter_size, num_features)]\n",
    "        for _ in range(1, num_conv_layers):\n",
    "            self.convlayers.append(Conv_layer(img, filter_size, num_features))\n",
    "        self.num_inputs_per_neuron = (img.shape[-1] * img.shape[-2]) * num_features**(num_conv_layers) \n",
    "\n",
    "        self.layers = [Layer(num_neurons_per_layer, self.num_inputs_per_neuron, device=device)]\n",
    "        for _ in range(1, num_conected_layers-1):\n",
    "            self.layers.append(Layer(num_neurons_per_layer, num_neurons_per_layer, device=device))\n",
    "        self.layers.append(Layer(num_final_out, num_neurons_per_layer, device=device))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=torch.zeros(1, requires_grad=True)\n",
    "        for i in range(0, num_conv_layers):\n",
    "            if i==0:\n",
    "                out = self.convlayers[0].forward_relu(x)\n",
    "            elif i==num_conv_layers-1:\n",
    "                out = self.convlayers[i].convolve(out)\n",
    "                out = out.reshape(self.num_inputs_per_neuron, batch_size)\n",
    "            else:\n",
    "                out = self.convlayers[i].forward_relu(out)\n",
    "                print(out.shape)\n",
    "\n",
    "        for i in range(0, num_connected_layers):\n",
    "            out = self.layers[i].forward(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def train(self, epochs, learning_rate):\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        for i in range(epochs):\n",
    "            x, y = self.datagen.data_generator()\n",
    "            out = self.forward(x).view(y.shape[0], y.shape[1])\n",
    "            # out = torch.tensor([-torch.inf if i.item()==0.0 else i for i in out.flatten()], device=device, requires_grad=True).view(y.shape[0], y.shape[1])\n",
    "            loss = loss_func(out, y) \n",
    "            # loss = ((y - out)**2).flatten().sum() \n",
    "            print(f\"Loss: {loss} at epoch: {i}\")\n",
    "            loss.backward()\n",
    "            for conv_layer in self.convlayers:\n",
    "                #manual clip grad, to be fixed\n",
    "                # w_grad = torch.tensor([c.item() if torch.abs(c) < 1000.0 else 1000.0 for c in conv_layer.w.grad.flatten()], dtype=torch.float, device=self.device)\n",
    "                # print(w_grad, \"\\n\", type(conv_layer.w.grad))\n",
    "                # conv_layer.w.grad = w_grad\n",
    "                # b_grad = torch.tensor([c.item() if torch.abs(c) < 100.0 else 100.0 for c in conv_layer.b.grad.flatten()], dtype=torch.float, device=self.device)\n",
    "                # conv_layer.b.grad = b_grad\n",
    "                conv_layer.w.data -= learning_rate * conv_layer.w.grad\n",
    "                conv_layer.b.data -= learning_rate * conv_layer.b.grad\n",
    "                conv_layer.w.grad = None\n",
    "                conv_layer.b.grad = None\n",
    "                \n",
    "            for layer in self.layers:\n",
    "                layer.w.data -= learning_rate * layer.w.grad\n",
    "                layer.b.data -= learning_rate * layer.b.grad\n",
    "                layer.w.grad = None\n",
    "                layer.b.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datagen:\n",
    "    def __init__(self, batch_size) -> None:\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def one_hot_encoder(self, y):\n",
    "            y_out = []\n",
    "            for i in y:\n",
    "                # num = np.array([-torch.inf for _ in range(num_classifications)])\n",
    "                num = np.zeros(num_classifications)\n",
    "                num[i] = 1\n",
    "                y_out.append(num)\n",
    "            return(torch.tensor(np.array(y_out), dtype=torch.float32)).to(device)\n",
    "    \n",
    "    def data_generator(self, fix_seed=False, train=True):\n",
    "        if train:\n",
    "            train_data = pd.read_csv(\"/Users/adityatandon/Documents/VS Code/Learn ML/Data/MNIST/mnist_train.csv\")\n",
    "        else:\n",
    "            train_data = pd.read_csv(\"/Users/adityatandon/Documents/VS Code/Learn ML/Data/MNIST/mnist_test.csv\")\n",
    "        \n",
    "        if fix_seed==True:\n",
    "            seed_idx = torch.tensor(int(input(\"Enter seed index number\")))\n",
    "        else:\n",
    "            seed_idx = (torch.randint(low=0, high=len(train_data) - self.batch_size, size=(1,1))).item()\n",
    "        \n",
    "        y_out = torch.tensor(train_data['label'].iloc[seed_idx:seed_idx+self.batch_size].to_numpy()).to(device)\n",
    "        x = (torch.tensor(train_data.iloc[seed_idx:seed_idx+self.batch_size, 1:].to_numpy()).view(self.batch_size, 1, 28, 28).to(device))\n",
    "        y_out = self.one_hot_encoder(y_out)\n",
    "        return x, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = Datagen(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datagen.data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(num_connected_layers, num_conv_layers, num_neurons_per_layer, num_classifications, Datagen, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train(epochs=200, learning_rate=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.forward(x=x).view(y.shape[0], y.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
